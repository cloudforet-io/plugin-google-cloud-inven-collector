import logging
from typing import List

from spaceone.inventory.libs.connector import GoogleCloudConnector

__all__ = ["FirestoreDatabaseConnector"]
_LOGGER = logging.getLogger(__name__)


class FirestoreDatabaseConnector(GoogleCloudConnector):
    google_client_service = "firestore"
    version = "v1"

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._database_clients = {}  # ë°ì´í„°ë² ì´ìŠ¤ë³„ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ

    def _get_admin_client(self, database_id="(default)"):
        """Firestore Admin SDK í´ë¼ì´ì–¸íŠ¸ë¥¼ lazy loadingìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            database_id: ë°ì´í„°ë² ì´ìŠ¤ ID (ê¸°ë³¸ê°’: "(default)")

        Returns:
            Admin SDK í´ë¼ì´ì–¸íŠ¸ (ë°ì´í„°ë² ì´ìŠ¤ë³„ ìºì‹œë¨)
        """
        # ë°ì´í„°ë² ì´ìŠ¤ë³„ í´ë¼ì´ì–¸íŠ¸ ìºì‹±
        if database_id not in self._database_clients:
            try:
                from google.cloud import firestore

                # ë°ì´í„°ë² ì´ìŠ¤ë³„ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                if database_id == "(default)":
                    # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸
                    client = firestore.Client(
                        project=self.project_id, credentials=self.credentials
                    )
                else:
                    # íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸
                    client = firestore.Client(
                        project=self.project_id,
                        database=database_id,
                        credentials=self.credentials,
                    )

                self._database_clients[database_id] = client

            except ImportError:
                _LOGGER.error(
                    "google-cloud-firestore library not found. "
                    "Please install: pip install google-cloud-firestore"
                )
                raise
            except Exception as e:
                _LOGGER.error(
                    f"Failed to initialize Firestore Admin SDK client for {database_id}: {e}"
                )
                raise

        return self._database_clients[database_id]

    def list_databases(self, **query):
        """Firestore ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            **query: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

        Returns:
            List[dict]: ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡
        """
        database_list = []
        query.update({"parent": f"projects/{self.project_id}"})

        request = self.client.projects().databases().list(**query)
        while request is not None:
            response = request.execute()
            all_databases = response.get("databases", [])
            # FIRESTORE_NATIVE íƒ€ì…ë§Œ í•„í„°ë§
            firestore_databases = list(
                filter(lambda db: db.get("type") == "FIRESTORE_NATIVE", all_databases)
            )
            database_list.extend(firestore_databases)
            # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬ - list_nextê°€ ìˆëŠ”ì§€ í™•ì¸
            try:
                request = (
                    self.client.projects()
                    .databases()
                    .list_next(previous_request=request, previous_response=response)
                )
            except AttributeError:
                # list_nextê°€ ì—†ëŠ” ê²½ìš° ì²« í˜ì´ì§€ë§Œ ì²˜ë¦¬
                break

        return database_list

    def list_indexes(self, database_name, **query):
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¸ë±ìŠ¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            database_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
            **query: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

        Returns:
            List[dict]: ì¸ë±ìŠ¤ ëª©ë¡
        """
        indexes = []
        parent = f"{database_name}/collectionGroups/-"

        query.update({"parent": parent})

        request = (
            self.client.projects()
            .databases()
            .collectionGroups()
            .indexes()
            .list(**query)
        )
        while request is not None:
            response = request.execute()
            indexes.extend(response.get("indexes", []))
            # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬ - list_nextê°€ ìˆëŠ”ì§€ í™•ì¸
            try:
                request = (
                    self.client.projects()
                    .databases()
                    .collectionGroups()
                    .indexes()
                    .list_next(previous_request=request, previous_response=response)
                )
            except AttributeError:
                # list_nextê°€ ì—†ëŠ” ê²½ìš° ì²« í˜ì´ì§€ë§Œ ì²˜ë¦¬
                break

        return indexes

    def list_collections_with_documents(self, database_name, parent="", **query):
        """ì»¬ë ‰ì…˜ IDì™€ ê° ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œë“¤ì„ í•œ ë²ˆì— ì¡°íšŒí•©ë‹ˆë‹¤. (ìµœì í™”ëœ í†µí•© ë©”ì„œë“œ)

        ì´ ë©”ì„œë“œëŠ” ê¸°ì¡´ list_collection_ids + list_documentsì˜ ì¤‘ë³µ í˜¸ì¶œì„ ë°©ì§€í•˜ì—¬
        ë™ì¼í•œ parentì— ëŒ€í•œ admin_client.document() í˜¸ì¶œì„ ìµœì í™”í•©ë‹ˆë‹¤.

        Args:
            database_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
            parent: ë¶€ëª¨ ë¬¸ì„œ ê²½ë¡œ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ìµœìƒìœ„)
            **query: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

        Returns:
            List[dict]: ì»¬ë ‰ì…˜ ì •ë³´ì™€ ë¬¸ì„œë“¤ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ ëª©ë¡
            [
                {
                    "collection_id": str,
                    "documents": List[dict],
                }
            ]
        """
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ID ì¶”ì¶œ
            database_id = "(default)"
            if "/databases/" in database_name:
                database_id = database_name.split("/databases/")[-1]

            # ğŸ¯ ìµœì í™”: ë°ì´í„°ë² ì´ìŠ¤ë³„ ìºì‹œëœ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
            admin_client = self._get_admin_client(database_id)

            collections_with_docs = []
            page_size = query.get("pageSize", 100)

            if not parent:
                # ìµœìƒìœ„ ì»¬ë ‰ì…˜ë“¤ ì²˜ë¦¬
                collections = admin_client.collections()

                for collection in collections:
                    collection_id = collection.id

                    # í•´ë‹¹ ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œë“¤ ì¡°íšŒ
                    documents = []
                    try:
                        docs_stream = collection.limit(page_size).stream()
                        for doc in docs_stream:
                            doc_dict = {
                                "name": doc.reference.path,
                                "fields": doc.to_dict(),
                                "createTime": doc.create_time.isoformat()
                                if doc.create_time
                                else None,
                                "updateTime": doc.update_time.isoformat()
                                if doc.update_time
                                else None,
                            }
                            documents.append(doc_dict)
                    except Exception as e:
                        _LOGGER.warning(
                            f"Failed to get documents for collection {collection_id}: {e}"
                        )

                    collections_with_docs.append(
                        {
                            "collection_id": collection_id,
                            "documents": documents,
                        }
                    )

            else:
                # í•˜ìœ„ ì»¬ë ‰ì…˜ë“¤ ì²˜ë¦¬ (ë‹¨ì¼ document() í˜¸ì¶œë¡œ ìµœì í™”)
                parent_doc_ref = admin_client.document(parent)  # í•œ ë²ˆë§Œ í˜¸ì¶œ!

                # í•˜ìœ„ ì»¬ë ‰ì…˜ë“¤ ì¡°íšŒ
                subcollections = parent_doc_ref.collections()

                for collection in subcollections:
                    collection_id = collection.id

                    # í•´ë‹¹ ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œë“¤ ì¡°íšŒ (ì´ë¯¸ ì–»ì€ collection ì°¸ì¡° ì‚¬ìš©)
                    documents = []
                    try:
                        docs_stream = collection.limit(page_size).stream()
                        for doc in docs_stream:
                            doc_dict = {
                                "name": doc.reference.path,
                                "fields": doc.to_dict(),
                                "createTime": doc.create_time.isoformat()
                                if doc.create_time
                                else None,
                                "updateTime": doc.update_time.isoformat()
                                if doc.update_time
                                else None,
                            }
                            documents.append(doc_dict)
                    except Exception as e:
                        _LOGGER.warning(
                            f"Failed to get documents for subcollection {collection_id}: {e}"
                        )

                    collections_with_docs.append(
                        {
                            "collection_id": collection_id,
                            "documents": documents,
                        }
                    )

            _LOGGER.debug(
                f"Retrieved {len(collections_with_docs)} collections with documents"
            )
            return collections_with_docs

        except Exception as e:
            _LOGGER.error(
                f"Failed to list collections with documents using Admin SDK for parent '{parent}': {e}"
            )
            return []

    def list_backup_schedules(self, database_name: str, **query) -> List[dict]:
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°±ì—… ìŠ¤ì¼€ì¤„ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            database_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (projects/{project}/databases/{database} í˜•ì‹)
            **query: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

        Returns:
            List[dict]: ë°±ì—… ìŠ¤ì¼€ì¤„ ëª©ë¡
        """
        backup_schedules = []

        try:
            query.update({"parent": database_name})

            request = self.client.projects().databases().backupSchedules().list(**query)

            while request is not None:
                response = request.execute()
                backup_schedules.extend(response.get("backupSchedules", []))

                # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
                try:
                    request = (
                        self.client.projects()
                        .databases()
                        .backupSchedules()
                        .list_next(previous_request=request, previous_response=response)
                    )
                except AttributeError:
                    # list_nextê°€ ì—†ëŠ” ê²½ìš° ì²« í˜ì´ì§€ë§Œ ì²˜ë¦¬
                    break

            _LOGGER.debug(
                f"Retrieved {len(backup_schedules)} backup schedules for {database_name}"
            )
            return backup_schedules

        except Exception as e:
            _LOGGER.error(f"Failed to list backup schedules for {database_name}: {e}")
            return []

    def list_all_backups(self, **query) -> List[dict]:
        """í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ìœ„ì¹˜ì—ì„œ ë°±ì—… ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        location='-'ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ìœ„ì¹˜ì˜ ë°±ì—…ì„ í•œ ë²ˆì— íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            **query: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

        Returns:
            List[dict]: ëª¨ë“  ìœ„ì¹˜ì˜ ë°±ì—… ëª©ë¡
        """
        backups = []

        try:
            # location='-'ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ìœ„ì¹˜ì˜ ë°±ì—…ì„ í•œ ë²ˆì— ì¡°íšŒ
            parent = f"projects/{self.project_id}/locations/-"
            query.update({"parent": parent})

            request = self.client.projects().locations().backups().list(**query)

            while request is not None:
                response = request.execute()
                backups.extend(response.get("backups", []))

                # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
                try:
                    request = (
                        self.client.projects()
                        .locations()
                        .backups()
                        .list_next(previous_request=request, previous_response=response)
                    )
                except AttributeError:
                    # list_nextê°€ ì—†ëŠ” ê²½ìš° ì²« í˜ì´ì§€ë§Œ ì²˜ë¦¬
                    break

            _LOGGER.info(
                f"Retrieved {len(backups)} backups from all locations for project {self.project_id}"
            )
            return backups

        except Exception as e:
            _LOGGER.error(
                f"Failed to list backups from all locations for project {self.project_id}: {e}"
            )
            return []
